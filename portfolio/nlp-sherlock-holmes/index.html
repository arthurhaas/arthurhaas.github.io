<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>NLP with Sherlock Holmes | arthurhaas.github.io</title><meta name=keywords content="natural language processing"><meta name=description content="Description In a group of two, we worked on a project for the master&rsquo;s course &ldquo;Information Retrieval and Text Mining&rdquo;. This project retrieves information from the Sherlock Holmes stories by using a number of text mining techniques and validates their correctness with quality measures based on a kappa distance verified dataset after adding annotations with tagtog.
This text mining project concerned the analysis of all 60 Sherlock Holmes narratives. During the project, we preprocessed the stories, created a validation set for the Stanford coreNLP NER annotator by using tagtog on 100 data samples with 4 independent judges."><meta name=author content="Arthur"><link rel=canonical href=https://arthurhaas.github.io/portfolio/nlp-sherlock-holmes/><link crossorigin=anonymous href=/assets/css/stylesheet.min.e1aed7acf69d338b310ccd197719ef7a7d747001df7045f014fe3ff31980530b.css integrity="sha256-4a7XrPadM4sxDM0Zdxnven10cAHfcEXwFP4/8xmAUws=" rel="preload stylesheet" as=style><link rel=preload href=images/avatar.png as=image><script defer crossorigin=anonymous src=/assets/js/highlight.min.b95bacdc39e37a332a9f883b1e78be4abc1fdca2bc1f2641f55e3cd3dabd4d61.js integrity="sha256-uVus3DnjejMqn4g7Hni+Srwf3KK8HyZB9V4809q9TWE=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://arthurhaas.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://arthurhaas.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://arthurhaas.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://arthurhaas.github.io/apple-touch-icon.png><link rel=mask-icon href=https://arthurhaas.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><meta name=generator content="Hugo 0.110.0"><meta property="og:title" content="NLP with Sherlock Holmes"><meta property="og:description" content="Description In a group of two, we worked on a project for the master&rsquo;s course &ldquo;Information Retrieval and Text Mining&rdquo;. This project retrieves information from the Sherlock Holmes stories by using a number of text mining techniques and validates their correctness with quality measures based on a kappa distance verified dataset after adding annotations with tagtog.
This text mining project concerned the analysis of all 60 Sherlock Holmes narratives. During the project, we preprocessed the stories, created a validation set for the Stanford coreNLP NER annotator by using tagtog on 100 data samples with 4 independent judges."><meta property="og:type" content="article"><meta property="og:url" content="https://arthurhaas.github.io/portfolio/nlp-sherlock-holmes/"><meta property="og:image" content="https://arthurhaas.github.io/images/portfolio/nlp-sherlock-holmes/book-2795850_640.png"><meta property="article:section" content="portfolio"><meta property="article:published_time" content="2021-05-27T12:42:00+01:00"><meta property="article:modified_time" content="2021-05-27T12:42:00+01:00"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://arthurhaas.github.io/images/portfolio/nlp-sherlock-holmes/book-2795850_640.png"><meta name=twitter:title content="NLP with Sherlock Holmes"><meta name=twitter:description content="Description In a group of two, we worked on a project for the master&rsquo;s course &ldquo;Information Retrieval and Text Mining&rdquo;. This project retrieves information from the Sherlock Holmes stories by using a number of text mining techniques and validates their correctness with quality measures based on a kappa distance verified dataset after adding annotations with tagtog.
This text mining project concerned the analysis of all 60 Sherlock Holmes narratives. During the project, we preprocessed the stories, created a validation set for the Stanford coreNLP NER annotator by using tagtog on 100 data samples with 4 independent judges."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Portfolio","item":"https://arthurhaas.github.io/portfolio/"},{"@type":"ListItem","position":3,"name":"NLP with Sherlock Holmes","item":"https://arthurhaas.github.io/portfolio/nlp-sherlock-holmes/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"NLP with Sherlock Holmes","name":"NLP with Sherlock Holmes","description":"Description In a group of two, we worked on a project for the master\u0026rsquo;s course \u0026ldquo;Information Retrieval and Text Mining\u0026rdquo;. This project retrieves information from the Sherlock Holmes stories by using a number of text mining techniques and validates their correctness with quality measures based on a kappa distance verified dataset after adding annotations with tagtog.\nThis text mining project concerned the analysis of all 60 Sherlock Holmes narratives. During the project, we preprocessed the stories, created a validation set for the Stanford coreNLP NER annotator by using tagtog on 100 data samples with 4 independent judges.","keywords":["natural language processing"],"articleBody":"Description In a group of two, we worked on a project for the master’s course “Information Retrieval and Text Mining”. This project retrieves information from the Sherlock Holmes stories by using a number of text mining techniques and validates their correctness with quality measures based on a kappa distance verified dataset after adding annotations with tagtog.\nThis text mining project concerned the analysis of all 60 Sherlock Holmes narratives. During the project, we preprocessed the stories, created a validation set for the Stanford coreNLP NER annotator by using tagtog on 100 data samples with 4 independent judges. The Kappa distance agreement for the entity type person reached 91.7% and for location 81.6%, thus enabling us to use the validation set. The coreNLP NER annotator was verified on the validation set and received a recall score of 80% for persons and 79% for locations thus allowing us to continue with this parser.\nFor the core text mining techniques, we firstly extracted vocabulary using lemmatization by story for the exploratory data analysis to introduce the reader to the publications. Next, we optimized the Stanford’s coreNLP parser for Sherlock Holmes stories by research about parser options and using custom rules sets to achieve higher quality. We further analyzed POS tags and named entities in different settings after normalizing character names using a combination of distance measures. Based on named entities another information retrieval technique was applied to retrieve a social network between characters based on the token distance of their names in all stories. Visualisations were generated using the desktop visualization tool Tableau and Gephi.\nFinally, we learned that preprocessing and parsing for text mining projects take up a large part of the time. Particularly the constant iterations to improve their quality were challenging. Here we helped ourselves by applying software engineering to automate repetitive tasks and to create helper functions for common methods.\nThis project is on GitHub: https://github.com/arthurhaas/um_2021_text_mining\nA few selected results /1 A first exploratory data analysis is performed to introduce the reader to the Sherlock Holmes stories in the dataset. It shows all 56 stories and 4 novels of Sir Arthur Conan Doyle, in ascending order by publishing date and grouped by the collection. From this visualization, it can be seen, that Sir Doyle first wrote two novels before starting with the shorter stories. While the first three collections The Adventures of Sherlock Holmes, The Memoirs of Sherlock Holmes and The Return of Sherlock Holmes were written in a short period of time, his latter two collections His Last Bow and The Case Book of Sherlock Holmes were spread over several years. Most interestingly it is visible, that one story from January 1893, called The Adventure of the Cardboard Box was originally written while creating the second collection of stories, but later this story was assigned to the fourth collection.\nPublications by year and month\n/2 Another very interesting view on the dataset is the analysis by vocabulary size. It shows again all 56 stories and 4 novels in ascending order by publishing date. The bars indicate the vocabulary size after lemmatization with the color indicating the collection. The line shows the same vocabulary but cumulatively counted over the years. With the last story published in March 1927, Sir Doyle used a total of around 15,000 distinct words. It is not surprising that the stories contain a smaller vocabulary than the novels because these are shorter in general. Moreover, Sir Doyle was able to constantly increase his vocabulary, although it is visible, that the latter stories from the last collection (in green) seem to use a lower vocabulary size. Used Vocabulary by Conan Doyle over his works on Sherlock Holmes\n/3 For the visualization of the co-occurrences of the characters the tool we have chosen is Gephi. As input two files were given, one containing information about the nodes, one about the edges. We adjusted the sizes of the nodes based on their degree first and then on the betweenness centrality metric. The sizes of the edges were set according to their weights which is based on the closeness of the characters. Parallel with the size of the nodes and edges the color of them also changes from lighter to darker to make it more aesthetic visually. Network of John H. Watson based on the betweenness centrality measure in the co-occurrence network.\npssst.. can you spot the mistake? If yes, well yeah, there is always some space for improvement ;)\n--\nImage by bluebudgie from Pixabay\n","wordCount":"747","inLanguage":"en","image":"https://arthurhaas.github.io/images/portfolio/nlp-sherlock-holmes/book-2795850_640.png","datePublished":"2021-05-27T12:42:00+01:00","dateModified":"2021-05-27T12:42:00+01:00","author":{"@type":"Person","name":"Arthur"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://arthurhaas.github.io/portfolio/nlp-sherlock-holmes/"},"publisher":{"@type":"Organization","name":"arthurhaas.github.io","logo":{"@type":"ImageObject","url":"https://arthurhaas.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"&&document.body.classList.add("dark")</script><noscript><style type=text/css>#theme-toggle,.top-link{display:none}</style></noscript><header class=header><nav class=nav><div class=logo><a href=https://arthurhaas.github.io accesskey=h title="arthurhaas.github.io (Alt + H)">arthurhaas.github.io</a>
<span class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></span></div><ul id=menu><li><a href=https://arthurhaas.github.io/pages/about title="about me"><span>about me</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://arthurhaas.github.io>Home</a>&nbsp;»&nbsp;<a href=https://arthurhaas.github.io/portfolio/>Portfolio</a></div><h1 class=post-title>NLP with Sherlock Holmes</h1><div class=post-meta>May 27, 2021&nbsp;·&nbsp;Arthur</div></header><figure class=entry-cover><img loading=lazy src=https://arthurhaas.github.io/images/portfolio/nlp-sherlock-holmes/book-2795850_640.png alt="knowledge graph"><p>Extract of final knowledge graph</p></figure><div class=toc><details open><summary accesskey=c title="(Alt + C)"><div class=details>Table of Contents</div></summary><div class=inner><ul><li><a href=#description aria-label=Description>Description</a></li><li><a href=#a-few-selected-results aria-label="A few selected results">A few selected results</a></li></ul></div></details></div><div class=post-content><h3 id=description>Description<a hidden class=anchor aria-hidden=true href=#description>#</a></h3><p>In a group of two, we worked on a project for the master&rsquo;s course &ldquo;Information Retrieval and Text Mining&rdquo;. This project retrieves information from the Sherlock Holmes stories by using a number of text mining techniques and validates their correctness with quality measures based on a kappa distance verified dataset after adding annotations with <a href=https://www.tagtog.net target=_blank rel=noopener>tagtog</a>.</p><p>This text mining project concerned the analysis of all 60 Sherlock Holmes narratives. During the project, we preprocessed the stories, created a validation set for the <a href=https://stanfordnlp.github.io/CoreNLP/index.html target=_blank rel=noopener>Stanford coreNLP</a> NER annotator by using tagtog on 100 data samples with 4 independent judges. The <a href=https://towardsdatascience.com/multi-class-metrics-made-simple-the-kappa-score-aka-cohens-kappa-coefficient-bdea137af09c target=_blank rel=noopener>Kappa distance agreement</a> for the entity type person reached 91.7% and for location 81.6%, thus enabling us to use the validation set. The coreNLP NER annotator was verified on the validation set and received a recall score of 80% for persons and 79% for locations thus allowing us to continue with this parser.</p><p>For the core text mining techniques, we firstly extracted vocabulary using lemmatization by story for the exploratory data analysis to introduce the reader to the publications. Next, we optimized the Stanford’s coreNLP parser for Sherlock Holmes stories by research about parser options and using custom rules sets to achieve higher quality. We further analyzed POS tags and named entities in different settings after normalizing character names using a combination of distance measures. Based on named entities another information retrieval technique was applied to retrieve a social network between characters based on the token distance of their names in all stories. Visualisations were generated using the desktop visualization tool <a href=https://www.tableau.com target=_blank rel=noopener>Tableau</a> and <a href=https://gephi.org target=_blank rel=noopener>Gephi</a>.</p><p>Finally, we learned that preprocessing and parsing for text mining projects take up a large part of the time. Particularly the constant iterations to improve their quality were challenging. Here we helped ourselves by applying software engineering to automate repetitive tasks and to create <a href=https://github.com/arthurhaas/um_2021_text_mining/tree/main/helper target=_blank rel=noopener>helper functions</a> for common methods.</p><p>This project is on GitHub: <a href=https://github.com/arthurhaas/um_2021_text_mining target=_blank rel=noopener>https://github.com/arthurhaas/um_2021_text_mining</a></p><h3 id=a-few-selected-results>A few selected results<a hidden class=anchor aria-hidden=true href=#a-few-selected-results>#</a></h3><p>/1
A first exploratory data analysis is performed to introduce the reader to the Sherlock Holmes stories in the dataset. It shows all 56 stories and 4 novels of Sir Arthur Conan Doyle, in ascending order by publishing date and grouped by the collection. From this visualization, it can be seen, that Sir Doyle first wrote two novels before starting with the shorter stories. While the first three collections The Adventures of Sherlock Holmes, The Memoirs of Sherlock Holmes and The Return of Sherlock Holmes were written in a short period of time, his latter two collections His Last Bow and The Case Book of Sherlock Holmes were spread over several years. Most interestingly it is visible, that one story from January 1893, called The Adventure of the Cardboard Box was originally written while creating the second collection of stories, but later this story was assigned to the fourth collection.</p><figure><img loading=lazy src=/images/portfolio/nlp-sherlock-holmes/eda_publications.png alt="Publications by year and month"><figcaption><p>Publications by year and month</p></figcaption></figure><p>/2
Another very interesting view on the dataset is the analysis by vocabulary size. It shows again all 56 stories and 4 novels in ascending order by publishing date. The bars indicate the vocabulary size after lemmatization with the color indicating the collection. The line shows the same vocabulary but cumulatively counted over the years. With the last story published in March 1927, Sir Doyle used a total of around 15,000 distinct words. It is not surprising that the stories contain a smaller vocabulary than the novels because these are shorter in general. Moreover, Sir Doyle was able to constantly increase his vocabulary, although it is visible, that the latter stories from the last collection (in green) seem to use a lower vocabulary size.<figure><img loading=lazy src=/images/portfolio/nlp-sherlock-holmes/eda_vocab.png alt="Vocabulary by year and month"><figcaption><p>Used Vocabulary by Conan Doyle over his works on Sherlock Holmes</p></figcaption></figure></p><p>/3
For the visualization of the co-occurrences of the characters the tool we have chosen is Gephi. As input two files were given, one containing information about the nodes, one about the edges. We adjusted the sizes of the nodes based on their degree first and then on the betweenness centrality metric. The sizes of the edges were set according to their weights which is based on the closeness of the characters. Parallel with the size of the nodes and edges the color of them also changes from lighter to darker to make it more aesthetic visually.<figure><img loading=lazy src=/images/portfolio/nlp-sherlock-holmes/social-network.jpg alt="Social network around Watson"><figcaption><p>Network of John H. Watson based on the betweenness centrality measure in the co-occurrence network.</p></figcaption></figure>pssst.. can you spot the mistake? If yes, well yeah, there is always some space for improvement ;)</p><p>--</p><p>Image by <a href="https://pixabay.com/users/bluebudgie-4333174/?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=2795850">bluebudgie</a> from <a href="https://pixabay.com/?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=2795850">Pixabay</a></p></div><footer class=post-footer><ul class=post-tags><li><a href=https://arthurhaas.github.io/tags/natural-language-processing/>natural language processing</a></li></ul></footer></article></main><footer class=footer><span>&copy; 2023 <a href=https://arthurhaas.github.io>arthurhaas.github.io</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)"><button class=top-link id=top-link type=button accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></button></a>
<script>let menu=document.getElementById("menu");menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)},document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var TxtRotate=function(e,t,n){this.toRotate=t,this.el=e,this.loopNum=0,this.period=parseInt(n,10)||2e3,this.txt="",this.tick(),this.isDeleting=!1};TxtRotate.prototype.tick=function(){var e,n,s=this.loopNum%this.toRotate.length,t=this.toRotate[s];this.isDeleting?this.txt=t.substring(0,this.txt.length-1):this.txt=t.substring(0,this.txt.length+1),this.el.innerHTML='<span class="wrap">'+this.txt+"</span>",n=this,e=100-Math.random()*50,this.isDeleting&&(e/=2),!this.isDeleting&&this.txt===t?(e=this.period,this.isDeleting=!0):this.isDeleting&&this.txt===""&&(this.isDeleting=!1,this.loopNum++,e=500),setTimeout(function(){n.tick()},e)},window.onload=function(){for(var n,s,o,t=document.getElementsByClassName("txt-rotate"),e=0;e<t.length;e++)s=t[e].getAttribute("data-rotate"),o=t[e].getAttribute("data-period"),s&&new TxtRotate(t[e],JSON.parse(s),o);n=document.createElement("style"),n.type="text/css",n.innerHTML=".txt-rotate > .wrap { border-right: 0.08em solid #666 }",document.body.appendChild(n)}</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerText="copy";function s(){t.innerText="copied!",setTimeout(()=>{t.innerText="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>