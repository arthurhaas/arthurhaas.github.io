<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Scientific Writing Assistant | arthurhaas.github.io</title><meta name=keywords content="natural language processing,SVM"><meta name=description content="During the master we are given a choice of projects to work on within one semester. This was one of them in a team of 6 students. The following text is taken from our GitHub repository:
This Master Research Project dealt with the creation and evaluation of a natural language processing tool to improve the scientific style of sentences without changing their semantic content. In a first step we have fine-tuned GPT-2 and T5 pretrained models using a previously proven pseudo-parallel dataset of original and paraphrased sentences to generate pseudo parallel data by paraphrasing a heavily filtered set of scientific sentences."><meta name=author content="Arthur"><link rel=canonical href=https://arthurhaas.github.io/portfolio/scientific-writing-assistant/><link crossorigin=anonymous href=/assets/css/stylesheet.min.e1aed7acf69d338b310ccd197719ef7a7d747001df7045f014fe3ff31980530b.css integrity="sha256-4a7XrPadM4sxDM0Zdxnven10cAHfcEXwFP4/8xmAUws=" rel="preload stylesheet" as=style><link rel=preload href=images/avatar.png as=image><script defer crossorigin=anonymous src=/assets/js/highlight.min.b95bacdc39e37a332a9f883b1e78be4abc1fdca2bc1f2641f55e3cd3dabd4d61.js integrity="sha256-uVus3DnjejMqn4g7Hni+Srwf3KK8HyZB9V4809q9TWE=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://arthurhaas.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://arthurhaas.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://arthurhaas.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://arthurhaas.github.io/apple-touch-icon.png><link rel=mask-icon href=https://arthurhaas.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><meta name=generator content="Hugo 0.110.0"><meta property="og:title" content="Scientific Writing Assistant"><meta property="og:description" content="During the master we are given a choice of projects to work on within one semester. This was one of them in a team of 6 students. The following text is taken from our GitHub repository:
This Master Research Project dealt with the creation and evaluation of a natural language processing tool to improve the scientific style of sentences without changing their semantic content. In a first step we have fine-tuned GPT-2 and T5 pretrained models using a previously proven pseudo-parallel dataset of original and paraphrased sentences to generate pseudo parallel data by paraphrasing a heavily filtered set of scientific sentences."><meta property="og:type" content="article"><meta property="og:url" content="https://arthurhaas.github.io/portfolio/scientific-writing-assistant/"><meta property="og:image" content="https://arthurhaas.github.io/images/portfolio/scientific-writing-assistant/screenshot-web.png"><meta property="article:section" content="portfolio"><meta property="article:published_time" content="2021-06-25T12:42:00+01:00"><meta property="article:modified_time" content="2021-06-25T12:42:00+01:00"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://arthurhaas.github.io/images/portfolio/scientific-writing-assistant/screenshot-web.png"><meta name=twitter:title content="Scientific Writing Assistant"><meta name=twitter:description content="During the master we are given a choice of projects to work on within one semester. This was one of them in a team of 6 students. The following text is taken from our GitHub repository:
This Master Research Project dealt with the creation and evaluation of a natural language processing tool to improve the scientific style of sentences without changing their semantic content. In a first step we have fine-tuned GPT-2 and T5 pretrained models using a previously proven pseudo-parallel dataset of original and paraphrased sentences to generate pseudo parallel data by paraphrasing a heavily filtered set of scientific sentences."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Portfolio","item":"https://arthurhaas.github.io/portfolio/"},{"@type":"ListItem","position":3,"name":"Scientific Writing Assistant","item":"https://arthurhaas.github.io/portfolio/scientific-writing-assistant/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Scientific Writing Assistant","name":"Scientific Writing Assistant","description":"During the master we are given a choice of projects to work on within one semester. This was one of them in a team of 6 students. The following text is taken from our GitHub repository:\nThis Master Research Project dealt with the creation and evaluation of a natural language processing tool to improve the scientific style of sentences without changing their semantic content. In a first step we have fine-tuned GPT-2 and T5 pretrained models using a previously proven pseudo-parallel dataset of original and paraphrased sentences to generate pseudo parallel data by paraphrasing a heavily filtered set of scientific sentences.","keywords":["natural language processing","SVM"],"articleBody":"During the master we are given a choice of projects to work on within one semester. This was one of them in a team of 6 students. The following text is taken from our GitHub repository:\nThis Master Research Project dealt with the creation and evaluation of a natural language processing tool to improve the scientific style of sentences without changing their semantic content. In a first step we have fine-tuned GPT-2 and T5 pretrained models using a previously proven pseudo-parallel dataset of original and paraphrased sentences to generate pseudo parallel data by paraphrasing a heavily filtered set of scientific sentences. In this context we developed a new evaluation metric for diverse paraphrase generation. In a second step we fine-tuned GPT-2 and T5 models for style-transfer using filtered and cleaned sentences from the previously created pseudo-parallel data. We then evaluated the performance of these models based on classifiers that we developed in the scope of our research questions.\nOur research goal was to find techniques for evaluating the performance of said scientific style transfer models. Because the scientificity of a sentence is manifold, we applied a combination of measures and models to validate the success of style transfer and the success of semantic preservation. For the evaluation of style transfer we used a RoBERTa classifier trained on sentences with TF-IDF masked tokens as well as an SVM model using handcrafted features. We found that this TF-IDF masking is necessary to ensure such classifiers do operate on style and not on content of the corpora they are trained on. For the semantic preservation we applied Moverscore and doing so critically discussed the applicability and the shortcomings of this novel metric. Moreover, we trained a classifier on the CoLA dataset to assess fluency of the output of our model. We also reviewed the performance of this classifier more critically than related work has done.\nFinally, we find as a bottom line to our report, that our defined target group of users for whom this scientific style transfer model will be useful are students, as evaluation shows the most success in style transfer on student reports. However, our analysis also shows that the developed model is not yet sufficiently robust for reliable performance, as some sentences loose scientificity during transfer (especially already scientific ones) and as human evaluation did not achieve the desired results.\nAfter submitting the university project and giving the final presentation, we worked hard to submit our work to the EMNLP 2021 Demo Track. This included writing a paper (in review), deploying our models to the Google Cloud Platform (let us know if you want to sponsor us) and creating a website in vue.js, which is accessible at http://writingassistant.ml.\nThe code is on Github: https://github.com/AcademiaAssistant/AcademiaWASP-LM\n","wordCount":"455","inLanguage":"en","image":"https://arthurhaas.github.io/images/portfolio/scientific-writing-assistant/screenshot-web.png","datePublished":"2021-06-25T12:42:00+01:00","dateModified":"2021-06-25T12:42:00+01:00","author":{"@type":"Person","name":"Arthur"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://arthurhaas.github.io/portfolio/scientific-writing-assistant/"},"publisher":{"@type":"Organization","name":"arthurhaas.github.io","logo":{"@type":"ImageObject","url":"https://arthurhaas.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"&&document.body.classList.add("dark")</script><noscript><style type=text/css>#theme-toggle,.top-link{display:none}</style></noscript><header class=header><nav class=nav><div class=logo><a href=https://arthurhaas.github.io accesskey=h title="arthurhaas.github.io (Alt + H)">arthurhaas.github.io</a>
<span class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></span></div><ul id=menu><li><a href=https://arthurhaas.github.io/pages/about title="about me"><span>about me</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://arthurhaas.github.io>Home</a>&nbsp;»&nbsp;<a href=https://arthurhaas.github.io/portfolio/>Portfolio</a></div><h1 class=post-title>Scientific Writing Assistant</h1><div class=post-meta>June 25, 2021&nbsp;·&nbsp;Arthur</div></header><figure class=entry-cover><img loading=lazy src=https://arthurhaas.github.io/images/portfolio/scientific-writing-assistant/screenshot-web.png alt="screenshot of our writingassistant"><p>Screenshot of www.writingassistant.ml</p></figure><div class=post-content><p>During the master we are given a choice of projects to work on within one semester. This was one of them in a team of 6 students. The following text is taken from our <a href=https://github.com/AcademiaAssistant/AcademiaWASP-LM target=_blank rel=noopener>GitHub repository</a>:</p><blockquote><p>This Master Research Project dealt with the creation and evaluation of a natural language processing tool to improve the scientific style of sentences without changing their semantic content. In a first step we have fine-tuned GPT-2 and T5 pretrained models using a previously proven pseudo-parallel dataset of original and paraphrased sentences to generate pseudo parallel data by paraphrasing a heavily filtered set of scientific sentences. In this context we developed a new evaluation metric for diverse paraphrase generation. In a second step we fine-tuned GPT-2 and T5 models for style-transfer using filtered and cleaned sentences from the previously created pseudo-parallel data. We then evaluated the performance of these models based on classifiers that we developed in the scope of our research questions.</p><p>Our research goal was to find techniques for evaluating the performance of said scientific style transfer models. Because the scientificity of a sentence is manifold, we applied a combination of measures and models to validate the success of style transfer and the success of semantic preservation. For the evaluation of style transfer we used a RoBERTa classifier trained on sentences with TF-IDF masked tokens as well as an SVM model using handcrafted features. We found that this TF-IDF masking is necessary to ensure such classifiers do operate on style and not on content of the corpora they are trained on. For the semantic preservation we applied Moverscore and doing so critically discussed the applicability and the shortcomings of this novel metric. Moreover, we trained a classifier on the CoLA dataset to assess fluency of the output of our model. We also reviewed the performance of this classifier more critically than related work has done.</p><p>Finally, we find as a bottom line to our report, that our defined target group of users for whom this scientific style transfer model will be useful are students, as evaluation shows the most success in style transfer on student reports. However, our analysis also shows that the developed model is not yet sufficiently robust for reliable performance, as some sentences loose scientificity during transfer (especially already scientific ones) and as human evaluation did not achieve the desired results.</p></blockquote><p>After submitting the university project and giving the final presentation, we worked hard to submit our work to the <a href=https://2021.emnlp.org target=_blank rel=noopener>EMNLP 2021 Demo Track</a>. This included writing a paper (in review), deploying our models to the Google Cloud Platform (let us know if you want to sponsor us) and creating a website in vue.js, which is accessible at <a href=http://writingassistant.ml target=_blank rel=noopener>http://writingassistant.ml</a>.</p><p>The code is on Github: <a href=https://github.com/AcademiaAssistant/AcademiaWASP-LM target=_blank rel=noopener>https://github.com/AcademiaAssistant/AcademiaWASP-LM</a></p></div><footer class=post-footer><ul class=post-tags><li><a href=https://arthurhaas.github.io/tags/natural-language-processing/>natural language processing</a></li><li><a href=https://arthurhaas.github.io/tags/svm/>SVM</a></li></ul></footer></article></main><footer class=footer><span>&copy; 2023 <a href=https://arthurhaas.github.io>arthurhaas.github.io</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)"><button class=top-link id=top-link type=button accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></button></a>
<script>let menu=document.getElementById("menu");menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)},document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var TxtRotate=function(e,t,n){this.toRotate=t,this.el=e,this.loopNum=0,this.period=parseInt(n,10)||2e3,this.txt="",this.tick(),this.isDeleting=!1};TxtRotate.prototype.tick=function(){var e,n,s=this.loopNum%this.toRotate.length,t=this.toRotate[s];this.isDeleting?this.txt=t.substring(0,this.txt.length-1):this.txt=t.substring(0,this.txt.length+1),this.el.innerHTML='<span class="wrap">'+this.txt+"</span>",n=this,e=100-Math.random()*50,this.isDeleting&&(e/=2),!this.isDeleting&&this.txt===t?(e=this.period,this.isDeleting=!0):this.isDeleting&&this.txt===""&&(this.isDeleting=!1,this.loopNum++,e=500),setTimeout(function(){n.tick()},e)},window.onload=function(){for(var n,s,o,t=document.getElementsByClassName("txt-rotate"),e=0;e<t.length;e++)s=t[e].getAttribute("data-rotate"),o=t[e].getAttribute("data-period"),s&&new TxtRotate(t[e],JSON.parse(s),o);n=document.createElement("style"),n.type="text/css",n.innerHTML=".txt-rotate > .wrap { border-right: 0.08em solid #666 }",document.body.appendChild(n)}</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerText="copy";function s(){t.innerText="copied!",setTimeout(()=>{t.innerText="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>