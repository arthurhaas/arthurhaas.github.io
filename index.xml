<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>arthurhaas.github.io</title><link>https://arthurhaas.github.io/</link><description>Recent content on arthurhaas.github.io</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Fri, 25 Jun 2021 12:42:00 +0100</lastBuildDate><atom:link href="https://arthurhaas.github.io/index.xml" rel="self" type="application/rss+xml"/><item><title>Scientific Writing Assistant</title><link>https://arthurhaas.github.io/portfolio/scientific-writing-assistant/</link><pubDate>Fri, 25 Jun 2021 12:42:00 +0100</pubDate><guid>https://arthurhaas.github.io/portfolio/scientific-writing-assistant/</guid><description>During the master we are given a choice of projects to work on within one semester. This was one of them in a team of 6 students. The following text is taken from our GitHub repository:
This Master Research Project dealt with the creation and evaluation of a natural language processing tool to improve the scientific style of sentences without changing their semantic content. In a first step we have fine-tuned GPT-2 and T5 pretrained models using a previously proven pseudo-parallel dataset of original and paraphrased sentences to generate pseudo parallel data by paraphrasing a heavily filtered set of scientific sentences.</description></item><item><title>NLP with Sherlock Holmes</title><link>https://arthurhaas.github.io/portfolio/nlp-sherlock-holmes/</link><pubDate>Thu, 27 May 2021 12:42:00 +0100</pubDate><guid>https://arthurhaas.github.io/portfolio/nlp-sherlock-holmes/</guid><description>Description In a group of two, we worked on a project for the master&amp;rsquo;s course &amp;ldquo;Information Retrieval and Text Mining&amp;rdquo;. This project retrieves information from the Sherlock Holmes stories by using a number of text mining techniques and validates their correctness with quality measures based on a kappa distance verified dataset after adding annotations with tagtog.
This text mining project concerned the analysis of all 60 Sherlock Holmes narratives. During the project, we preprocessed the stories, created a validation set for the Stanford coreNLP NER annotator by using tagtog on 100 data samples with 4 independent judges.</description></item><item><title>MusicBrainz Knowledge Graph</title><link>https://arthurhaas.github.io/portfolio/musicbrainz-knowledge-graph/</link><pubDate>Mon, 05 Apr 2021 12:42:00 +0100</pubDate><guid>https://arthurhaas.github.io/portfolio/musicbrainz-knowledge-graph/</guid><description>Motivation The master&amp;rsquo;s course &amp;ldquo;Building and Mining Knowledge Graphs&amp;rdquo; required us to work on an individual project. I decided to challenge myself with accessing and converting the MusicBrainz dataset into a knowledge graph before linking it to a few metrics for each country existing in it. Thereby deploying the MusicBrainz&amp;rsquo; postgreSQL database using docker, and focussing on the research of conversion by using three different approaches. The linking part on the other hand turned out to be too easy, hence I plan to connect the MusicBrainz dataset to my Spotify listening history in a follow-up project.</description></item><item><title>Personal Website</title><link>https://arthurhaas.github.io/portfolio/personal-website/</link><pubDate>Mon, 15 Feb 2021 12:42:00 +0100</pubDate><guid>https://arthurhaas.github.io/portfolio/personal-website/</guid><description>I built this website for a competition at Maastricht University. The goal was to create and deploy a static website using any static website generator out there. I decided to go with Hugo because of its great cli and high speed generating the site.
The theme I chose is papermod. It uses a nice minimalist design and receives regular updates. To implement the typing carousel on the profile page, I made use of a codepen which I had to adapt to my needs.</description></item><item><title>About me</title><link>https://arthurhaas.github.io/pages/about/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://arthurhaas.github.io/pages/about/</guid><description>As a second-year master&amp;rsquo;s student at Maastricht University, Netherlands, I study Data Science for Decision Making. My passion is to inspire people to do their best work by automating manual and tedious workflows, and to make their best decisions by extracting insights from data and representing it in useful visualizations for data-driven decision making.
Before my studies, I worked as a data analyst at shopping24 in Hamburg for several years. There I gained experiences with building a company-wide data lake, making this data available in the form of insightful analyses and Tableau dashboards for all teams, and setting up Apache Airflow.</description></item></channel></rss>